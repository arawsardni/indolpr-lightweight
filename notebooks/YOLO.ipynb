{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv11 Baseline for License Plate Detection\n",
    "\n",
    "This notebook implements the training pipeline for the License Plate Detection task using YOLOv11.\n",
    "\n",
    "**Steps:**\n",
    "1. **Setup**: Install `ultralytics`.\n",
    "2. **Data Preparation**: Convert the existing COCO format dataset to YOLO format.\n",
    "3. **Configuration**: Create the `data.yaml` file.\n",
    "4. **Training**: Train the YOLOv11 model.\n",
    "5. **Inference**: Test the model on sample images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ultralytics # Uncomment if you need to install via pip\n",
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "\n",
    "# Monkeypatch to bypass matplotlib font check issue causing RuntimeError\n",
    "try:\n",
    "    import ultralytics.utils.checks\n",
    "    import ultralytics.data.utils\n",
    "    \n",
    "    def patch_check_font(font):\n",
    "        print(f\"Skipping font check for {font} to avoid matplotlib error.\")\n",
    "        return\n",
    "\n",
    "    ultralytics.utils.checks.check_font = patch_check_font\n",
    "    ultralytics.data.utils.check_font = patch_check_font\n",
    "    print(\"Applied workaround for matplotlib font check.\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not apply font check patch: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Device count: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current device: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"WARNING: CUDA is not available. Training will be slow on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation (COCO to YOLO Conversion)\n",
    "\n",
    "We need to convert the COCO JSON annotations to YOLO `.txt` files.\n",
    "YOLO format: `class_id x_center y_center width height` (normalized 0-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "BASE_DIR = \"../datasets/IndonesianLiscenePlateDataset/plate_detection_dataset\"\n",
    "ANNOTATIONS_PATH = os.path.join(BASE_DIR, \"annotations/annotations.json\")\n",
    "IMAGES_DIR = os.path.join(BASE_DIR, \"images\")\n",
    "\n",
    "# Output Directory for YOLO Format\n",
    "YOLO_DATASET_DIR = \"../datasets/yolo_dataset\"\n",
    "\n",
    "# Create directories\n",
    "for split in ['train', 'val']:\n",
    "    os.makedirs(os.path.join(YOLO_DATASET_DIR, \"images\", split), exist_ok=True)\n",
    "    os.makedirs(os.path.join(YOLO_DATASET_DIR, \"labels\", split), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_coco_to_yolo(bbox, img_width, img_height):\n",
    "    \"\"\"\n",
    "    Converts COCO bbox [xmin, ymin, w, h] to YOLO bbox [x_center, y_center, w, h] normalized.\n",
    "    \"\"\"\n",
    "    x, y, w, h = bbox\n",
    "    \n",
    "    # Center coordinates\n",
    "    cx = x + w / 2\n",
    "    cy = y + h / 2\n",
    "    \n",
    "    # Normalize\n",
    "    cx /= img_width\n",
    "    cy /= img_height\n",
    "    w /= img_width\n",
    "    h /= img_height\n",
    "    \n",
    "    return [cx, cy, w, h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Annotations\n",
    "with open(ANNOTATIONS_PATH, 'r') as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "images = coco_data['images']\n",
    "annotations = coco_data['annotations']\n",
    "categories = coco_data['categories']\n",
    "\n",
    "# Create a map of image_id -> annotations\n",
    "img_ann_map = {img['id']: [] for img in images}\n",
    "for ann in annotations:\n",
    "    img_ann_map[ann['image_id']].append(ann)\n",
    "\n",
    "# Split Data\n",
    "train_imgs, val_imgs = train_test_split(images, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Train images: {len(train_imgs)}\")\n",
    "print(f\"Val images: {len(val_imgs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(image_list, split_name):\n",
    "    print(f\"Processing {split_name} data...\")\n",
    "    \n",
    "    for img_info in tqdm(image_list):\n",
    "        img_id = img_info['id']\n",
    "        file_name = img_info['file_name']\n",
    "        img_w = float(img_info['width'])\n",
    "        img_h = float(img_info['height'])\n",
    "        \n",
    "        # Source and Destination paths\n",
    "        src_img_path = os.path.join(IMAGES_DIR, file_name)\n",
    "        dst_img_path = os.path.join(YOLO_DATASET_DIR, \"images\", split_name, file_name)\n",
    "        \n",
    "        # Copy image\n",
    "        if os.path.exists(src_img_path):\n",
    "            shutil.copy(src_img_path, dst_img_path)\n",
    "        else:\n",
    "            print(f\"Warning: Image not found {src_img_path}\")\n",
    "            continue\n",
    "            \n",
    "        # Create Label File\n",
    "        label_file_name = os.path.splitext(file_name)[0] + \".txt\"\n",
    "        dst_label_path = os.path.join(YOLO_DATASET_DIR, \"labels\", split_name, label_file_name)\n",
    "        \n",
    "        anns = img_ann_map.get(img_id, [])\n",
    "        \n",
    "        with open(dst_label_path, 'w') as f:\n",
    "            for ann in anns:\n",
    "                # COCO category_id might not start at 0, YOLO expects 0-indexed\n",
    "                # Assuming 1 category 'license_plate', so class_id = 0\n",
    "                # If multiple, we need a map. Let's check categories.\n",
    "                # categories: [{'id': 1, 'name': 'license_plate'}]\n",
    "                # We'll map id 1 -> 0\n",
    "                \n",
    "                class_id = 0 # Since we only have one class\n",
    "                \n",
    "                bbox = ann['bbox']\n",
    "                yolo_bbox = convert_coco_to_yolo(bbox, img_w, img_h)\n",
    "                \n",
    "                f.write(f\"{class_id} {yolo_bbox[0]:.6f} {yolo_bbox[1]:.6f} {yolo_bbox[2]:.6f} {yolo_bbox[3]:.6f}\\n\")\n",
    "\n",
    "# Run conversion\n",
    "process_dataset(train_imgs, 'train')\n",
    "process_dataset(val_imgs, 'val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration (data.yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_yaml = {\n",
    "    'path': os.path.abspath(YOLO_DATASET_DIR),\n",
    "    'train': 'images/train',\n",
    "    'val': 'images/val',\n",
    "    'nc': 1,\n",
    "    'names': ['license_plate']\n",
    "}\n",
    "\n",
    "yaml_path = os.path.join(YOLO_DATASET_DIR, 'data.yaml')\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.dump(data_yaml, f, default_flow_style=False)\n",
    "    \n",
    "print(f\"Created data.yaml at {yaml_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training YOLOv11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"../models/yolo11n.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Train the model\n",
    "results = model.train(\n",
    "    data=yaml_path, \n",
    "    epochs=50, \n",
    "    imgsz=640, \n",
    "    batch=16,\n",
    "    project=\"../results/detection/yolo11_lpr\",\n",
    "    name=\"yolo11_run\",\n",
    "    device=0,\n",
    "    workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inference / Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate\n",
    "metrics = model.val()\n",
    "print(metrics.box.map)  # map50-95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on a sample image\n",
    "import random\n",
    "\n",
    "val_images_dir = os.path.join(YOLO_DATASET_DIR, \"images\", \"val\")\n",
    "sample_img = random.choice(os.listdir(val_images_dir))\n",
    "sample_img_path = os.path.join(val_images_dir, sample_img)\n",
    "\n",
    "results = model(sample_img_path)\n",
    "\n",
    "# Show result\n",
    "for r in results:\n",
    "    im_array = r.plot()  # plot a BGR numpy array of predictions\n",
    "    im_rgb = cv2.cvtColor(im_array, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(im_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (indolpr)",
   "language": "python",
   "name": "indolpr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

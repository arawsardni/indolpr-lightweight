{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR Baseline for License Plate Recognition (PaddleOCR)\n",
    "\n",
    "This notebook implements the OCR baseline using **PaddleOCR**.\n",
    "\n",
    "**Steps:**\n",
    "1. **Setup**: Install PaddlePaddle and PaddleOCR.\n",
    "2. **Data Preparation**: Convert dataset to PaddleOCR format.\n",
    "3. **Inference (Zero-shot)**: Test pre-trained model.\n",
    "4. **Training (Fine-tuning)**: Train a custom model on the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PaddlePaddle (GPU version recommended if available)\n",
    "# Check https://www.paddlepaddle.org.cn/en/install/quick for specific version\n",
    "# !python -m pip install paddlepaddle-gpu -i https://mirror.baidu.com/pypi/simple\n",
    "# !pip install paddleocr\n",
    "\n",
    "import paddle\n",
    "print(f\"PaddlePaddle Version: {paddle.__version__}\")\n",
    "print(f\"GPU Available: {paddle.device.is_compiled_with_cuda()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from paddleocr import PaddleOCR\n",
    "\n",
    "# Define Paths\n",
    "DATASET_DIR = \"../datasets/IndonesianLiscenePlateDataset/plate_text_dataset\"\n",
    "IMAGES_DIR = os.path.join(DATASET_DIR, \"dataset\")\n",
    "LABEL_FILE = os.path.join(DATASET_DIR, \"label.csv\")\n",
    "\n",
    "# Output for PaddleOCR training format\n",
    "PADDLE_DATA_DIR = \"../datasets/paddle_ocr_dataset\"\n",
    "os.makedirs(PADDLE_DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation\n",
    "\n",
    "PaddleOCR expects a text file where each line is: `path/to/image.jpg\\tlabel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Labels\n",
    "df = pd.read_csv(LABEL_FILE)\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "\n",
    "# Split Train/Val\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Train: {len(train_df)}, Val: {len(val_df)}\")\n",
    "\n",
    "def create_paddle_label_file(dataframe, output_path, relative_base_dir):\n",
    "    with open(output_path, 'w') as f:\n",
    "        for _, row in dataframe.iterrows():\n",
    "            filename = row['filename']\n",
    "            label = row['label']\n",
    "            \n",
    "            # Path relative to the folder where we will run training\n",
    "            # Usually we put images in the same dir or provide full path\n",
    "            # Let's use absolute paths to be safe, or relative to PADDLE_DATA_DIR\n",
    "            \n",
    "            # Source image path\n",
    "            src_path = os.path.join(IMAGES_DIR, filename)\n",
    "            if not os.path.exists(src_path):\n",
    "                print(f\"Warning: Image not found {src_path}\")\n",
    "                continue\n",
    "                \n",
    "            # We can symlink or copy, or just point to existing images\n",
    "            # Let's point to existing images using relative path from PADDLE_DATA_DIR\n",
    "            # PADDLE_DATA_DIR is ../datasets/paddle_ocr_dataset\n",
    "            # IMAGES_DIR is ../datasets/IndonesianLiscenePlateDataset/plate_text_dataset/dataset\n",
    "            # Rel path: ../IndonesianLiscenePlateDataset/plate_text_dataset/dataset/filename\n",
    "            \n",
    "            rel_path = os.path.relpath(src_path, PADDLE_DATA_DIR)\n",
    "            # PaddleOCR uses / as separator\n",
    "            rel_path = rel_path.replace(\"\\\\\", \"/\")\n",
    "            \n",
    "            f.write(f\"{rel_path}\\t{label}\\n\")\n",
    "            \n",
    "    print(f\"Created {output_path}\")\n",
    "\n",
    "create_paddle_label_file(train_df, os.path.join(PADDLE_DATA_DIR, \"rec_gt_train.txt\"), PADDLE_DATA_DIR)\n",
    "create_paddle_label_file(val_df, os.path.join(PADDLE_DATA_DIR, \"rec_gt_val.txt\"), PADDLE_DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Zero-shot Inference (Pre-trained Model)\n",
    "\n",
    "Check how the English pre-trained model performs on Indonesian plates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PaddleOCR\n",
    "try:\n",
    "    ocr = PaddleOCR(use_angle_cls=False, lang='en', use_gpu=True) \n",
    "    print(\"PaddleOCR initialized with GPU.\")\n",
    "except OSError as e:\n",
    "    print(f\"GPU Initialization failed: {e}\")\n",
    "    print(\"Falling back to CPU. Please check your PaddlePaddle and CUDA version compatibility.\")\n",
    "    ocr = PaddleOCR(use_angle_cls=False, lang='en', use_gpu=False)\n",
    "\n",
    "def predict_sample(image_path):\n",
    "    result = ocr.ocr(image_path, cls=False, det=False) # Only recognition\n",
    "    # result is a list of lists, e.g. [[('text', score)]]\n",
    "    if result and result[0]:\n",
    "        return result[0][0]\n",
    "    return None, 0.0\n",
    "\n",
    "# Test on a few validation samples\n",
    "sample_val = val_df.sample(5)\n",
    "\n",
    "for _, row in sample_val.iterrows():\n",
    "    img_path = os.path.join(IMAGES_DIR, row['filename'])\n",
    "    gt_label = row['label']\n",
    "    \n",
    "    pred_label, score = predict_sample(img_path)\n",
    "    \n",
    "    img = cv2.imread(img_path)\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f\"GT: {gt_label} | Pred: {pred_label} ({score:.2f})\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fine-tuning PaddleOCR\n",
    "\n",
    "To fine-tune, we need to clone the PaddleOCR repository and use their training script.\n",
    "This section assumes you are running in a Linux/Git Bash environment. If on Windows, commands might need adjustment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone PaddleOCR repo if not exists\n",
    "if not os.path.exists(\"PaddleOCR\"):\n",
    "    !git clone https://github.com/PaddlePaddle/PaddleOCR.git\n",
    "else:\n",
    "    print(\"PaddleOCR repo already cloned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements\n",
    "!pip install -r PaddleOCR/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "\n",
    "We need to create a config file (YAML) for training. We will base it on `en_PP-OCRv3_rec.yml`.\n",
    "Key changes needed:\n",
    "- `data_dir`: Path to our dataset\n",
    "- `label_file_list`: Path to our train/val txt files\n",
    "- `character_dict_path`: Path to character dictionary (use `en_dict.txt` or create custom)\n",
    "- `Global.epoch_num`: Number of epochs\n",
    "- `Global.save_model_dir`: Output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download pre-trained weights for fine-tuning\n",
    "# English PP-OCRv3 Recognition Model\n",
    "if not os.path.exists(\"en_PP-OCRv3_rec_train.tar\"):\n",
    "    !wget https://paddleocr.bj.bcebos.com/PP-OCRv3/english/en_PP-OCRv3_rec_train.tar\n",
    "    !tar -xf en_PP-OCRv3_rec_train.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom config file\n",
    "# We will read the default config and modify it\n",
    "\n",
    "base_config_path = \"PaddleOCR/configs/rec/PP-OCRv3/en_PP-OCRv3_rec.yml\"\n",
    "custom_config_path = \"PaddleOCR/configs/rec/PP-OCRv3/lpr_finetune.yml\"\n",
    "\n",
    "if os.path.exists(base_config_path):\n",
    "    with open(base_config_path, 'r') as f:\n",
    "        config_content = f.read()\n",
    "        \n",
    "    # Replace paths (Using absolute paths is safest)\n",
    "    abs_paddle_data_dir = os.path.abspath(PADDLE_DATA_DIR).replace(\"\\\\\", \"/\")\n",
    "    \n",
    "    # Modify config (Simple string replacement for demo, ideally use yaml parser)\n",
    "    config_content = config_content.replace(\"data_dir: ./train_data/\", f\"data_dir: {abs_paddle_data_dir}/\")\n",
    "    config_content = config_content.replace(\"label_file_list: ./train_data/train_list.txt\", f\"label_file_list: {abs_paddle_data_dir}/rec_gt_train.txt\")\n",
    "    config_content = config_content.replace(\"label_file_list: ./train_data/val_list.txt\", f\"label_file_list: {abs_paddle_data_dir}/rec_gt_val.txt\")\n",
    "    \n",
    "    # Set epochs and save dir\n",
    "    config_content = config_content.replace(\"epoch_num: 500\", \"epoch_num: 50\")\n",
    "    config_content = config_content.replace(\"save_model_dir: ./output/rec/en_PP-OCRv3\", \"save_model_dir: ../results/ocr/lpr_finetune\")\n",
    "    \n",
    "    # Set pretrained model path\n",
    "    abs_pretrained = os.path.abspath(\"../models/en_PP-OCRv3_rec_train/best_accuracy\").replace(\"\\\\\", \"/\")\n",
    "    config_content = config_content.replace(\"pretrained_model: \", f\"pretrained_model: {abs_pretrained}\")\n",
    "    \n",
    "    with open(custom_config_path, 'w') as f:\n",
    "        f.write(config_content)\n",
    "        \n",
    "    print(f\"Created custom config at {custom_config_path}\")\n",
    "else:\n",
    "    print(f\"Base config not found at {base_config_path}. Please check PaddleOCR structure.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Training\n",
    "# Note: This might take a while. You can monitor the output.\n",
    "# Ensure you are in the PaddleOCR directory or reference the script correctly.\n",
    "\n",
    "print(\"Starting training... (Uncomment line below to run)\")\n",
    "# !python PaddleOCR/tools/train.py -c PaddleOCR/configs/rec/PP-OCRv3/lpr_finetune.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation\n",
    "\n",
    "After training, evaluate the model using the best checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python PaddleOCR/tools/eval.py -c PaddleOCR/configs/rec/PP-OCRv3/lpr_finetune.yml -o Global.checkpoints=./output/rec/lpr_finetune/best_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
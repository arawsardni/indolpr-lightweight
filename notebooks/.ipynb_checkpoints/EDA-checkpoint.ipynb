{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA) for License Plate Recognition\n",
    "\n",
    "This notebook performs EDA on the License Plate Recognition project datasets:\n",
    "1. **Detection Dataset**: YOLO format (COCO annotations)\n",
    "2. **OCR Dataset**: PaddleOCR format (Images + Labels)\n",
    "\n",
    "The goal is to ensure dataset quality, identify anomalies, and understand data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import matplotlib.patches as patches\n",
    "import glob\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A: Detection Dataset EDA (YOLO - Bounding Box)\n",
    "\n",
    "We will analyze the COCO format annotations for the plate detection dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "DET_DATASET_PATH = \"../datasets/IndonesianLiscenePlateDataset/plate_detection_dataset\"\n",
    "ANNOTATIONS_PATH = os.path.join(DET_DATASET_PATH, \"annotations/annotations.json\")\n",
    "IMAGES_PATH = os.path.join(DET_DATASET_PATH, \"images\")\n",
    "\n",
    "# Load annotations\n",
    "if os.path.exists(ANNOTATIONS_PATH):\n",
    "    with open(ANNOTATIONS_PATH, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "    print(f\"Loaded annotations from {ANNOTATIONS_PATH}\")\n",
    "    print(f\"Keys: {coco_data.keys()}\")\n",
    "    print(f\"Number of images: {len(coco_data['images'])}\")\n",
    "    print(f\"Number of annotations: {len(coco_data['annotations'])}\")\n",
    "    print(f\"Number of categories: {len(coco_data['categories'])}\")\n",
    "else:\n",
    "    print(f\"Annotation file not found at {ANNOTATIONS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Image Size Distribution\n",
    "Check the distribution of image widths and heights. YOLO is sensitive to aspect ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'coco_data' in locals():\n",
    "    img_df = pd.DataFrame(coco_data['images'])\n",
    "    \n",
    "    # Ensure numeric types to avoid matplotlib TypeError\n",
    "    img_df['width'] = pd.to_numeric(img_df['width'], errors='coerce')\n",
    "    img_df['height'] = pd.to_numeric(img_df['height'], errors='coerce')\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(img_df['width'], kde=False, bins=20)\n",
    "    plt.title('Image Width Distribution')\n",
    "    plt.xlabel('Width')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.histplot(img_df['height'], kde=False, bins=20)\n",
    "    plt.title('Image Height Distribution')\n",
    "    plt.xlabel('Height')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Aspect Ratio\n",
    "    img_df['aspect_ratio'] = img_df['width'] / img_df['height']\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.histplot(img_df['aspect_ratio'], kde=True, bins=20)\n",
    "    plt.title('Image Aspect Ratio Distribution')\n",
    "    plt.xlabel('Aspect Ratio (Width/Height)')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Common Image Sizes (WxH):\")\n",
    "    print(img_df.groupby(['width', 'height']).size().sort_values(ascending=False).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Objects per Image\n",
    "Check how many bounding boxes are present in each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'coco_data' in locals():\n",
    "    ann_df = pd.DataFrame(coco_data['annotations'])\n",
    "    \n",
    "    # Count annotations per image\n",
    "    anns_per_img = ann_df.groupby('image_id').size()\n",
    "    \n",
    "    # Include images with 0 annotations\n",
    "    all_img_ids = set(img_df['id'])\n",
    "    ann_img_ids = set(anns_per_img.index)\n",
    "    zero_ann_imgs = len(all_img_ids - ann_img_ids)\n",
    "    \n",
    "    # Add 0 counts\n",
    "    counts = anns_per_img.value_counts().sort_index()\n",
    "    if zero_ann_imgs > 0:\n",
    "        counts[0] = zero_ann_imgs\n",
    "        counts = counts.sort_index()\n",
    "        \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.barplot(x=counts.index, y=counts.values)\n",
    "    plt.title('Number of Objects per Image')\n",
    "    plt.xlabel('Object Count')\n",
    "    plt.ylabel('Number of Images')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Images with 0 objects: {zero_ann_imgs}\")\n",
    "    print(f\"Images with >1 objects: {len(anns_per_img[anns_per_img > 1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualizing Sample Annotations\n",
    "Visualizing random samples to check bounding box quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample_annotations(coco_data, images_dir, num_samples=5):\n",
    "    import random\n",
    "    \n",
    "    img_ids = [img['id'] for img in coco_data['images']]\n",
    "    sample_ids = random.sample(img_ids, num_samples)\n",
    "    \n",
    "    plt.figure(figsize=(15, 5 * num_samples))\n",
    "    \n",
    "    for i, img_id in enumerate(sample_ids):\n",
    "        img_info = next(img for img in coco_data['images'] if img['id'] == img_id)\n",
    "        img_anns = [ann for ann in coco_data['annotations'] if ann['image_id'] == img_id]\n",
    "        \n",
    "        img_path = os.path.join(images_dir, img_info['file_name'])\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"Image not found: {img_path}\")\n",
    "            continue\n",
    "            \n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        plt.subplot(num_samples, 1, i+1)\n",
    "        plt.imshow(img)\n",
    "        \n",
    "        ax = plt.gca()\n",
    "        \n",
    "        for ann in img_anns:\n",
    "            bbox = ann['bbox'] # [x, y, width, height]\n",
    "            rect = patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], linewidth=2, edgecolor='r', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "            \n",
    "        plt.title(f\"Image: {img_info['file_name']} (ID: {img_id})\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if 'coco_data' in locals():\n",
    "    show_sample_annotations(coco_data, IMAGES_PATH, num_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bounding Box Distribution\n",
    "Analyze width, height, area, and aspect ratio of bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'coco_data' in locals():\n",
    "    # Extract bbox info\n",
    "    bboxes = [ann['bbox'] for ann in coco_data['annotations']]\n",
    "    bbox_df = pd.DataFrame(bboxes, columns=['x', 'y', 'w', 'h'])\n",
    "    \n",
    "    # Ensure numeric types\n",
    "    bbox_df['w'] = pd.to_numeric(bbox_df['w'], errors='coerce')\n",
    "    bbox_df['h'] = pd.to_numeric(bbox_df['h'], errors='coerce')\n",
    "    \n",
    "    bbox_df['area'] = bbox_df['w'] * bbox_df['h']\n",
    "    bbox_df['aspect_ratio'] = bbox_df['w'] / bbox_df['h']\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    sns.histplot(bbox_df['w'], kde=True)\n",
    "    plt.title('BBox Width Distribution')\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    sns.histplot(bbox_df['h'], kde=True)\n",
    "    plt.title('BBox Height Distribution')\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    sns.histplot(bbox_df['area'], kde=True)\n",
    "    plt.title('BBox Area Distribution')\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    sns.histplot(bbox_df['aspect_ratio'], kde=True)\n",
    "    plt.title('BBox Aspect Ratio Distribution')\n",
    "    plt.axvline(x=4, color='r', linestyle='--')\n",
    "    plt.axvline(x=6, color='r', linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"BBox Statistics:\")\n",
    "    print(bbox_df.describe())\n",
    "    \n",
    "    # Check for small plates\n",
    "    small_plates = bbox_df[bbox_df['h'] < 30]\n",
    "    print(f\"\\nPlates with height < 30px: {len(small_plates)} ({len(small_plates)/len(bbox_df)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Bounding Box Position Heatmap\n",
    "Check where the plates are located in the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'coco_data' in locals():\n",
    "    # Calculate centers\n",
    "    bbox_df['cx'] = bbox_df['x'] + bbox_df['w'] / 2\n",
    "    bbox_df['cy'] = bbox_df['y'] + bbox_df['h'] / 2\n",
    "    \n",
    "    # Create a map of image id to size\n",
    "    img_size_map = {img['id']: (float(img['width']), float(img['height'])) for img in coco_data['images']}\n",
    "    \n",
    "    norm_cx = []\n",
    "    norm_cy = []\n",
    "    \n",
    "    for ann in coco_data['annotations']:\n",
    "        img_w, img_h = img_size_map[ann['image_id']]\n",
    "        bbox = ann['bbox']\n",
    "        cx = bbox[0] + bbox[2] / 2\n",
    "        cy = bbox[1] + bbox[3] / 2\n",
    "        norm_cx.append(cx / img_w)\n",
    "        norm_cy.append(cy / img_h)\n",
    "        \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    sns.kdeplot(x=norm_cx, y=norm_cy, fill=True, cmap=\"Reds\", thresh=0.05)\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(1, 0) # Invert Y axis for image coordinates\n",
    "    plt.title('Bounding Box Center Heatmap (Normalized Coordinates)')\n",
    "    plt.xlabel('Normalized X')\n",
    "    plt.ylabel('Normalized Y')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Integrity Check\n",
    "Check for missing files or invalid annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'coco_data' in locals():\n",
    "    missing_images = []\n",
    "    for img in coco_data['images']:\n",
    "        img_path = os.path.join(IMAGES_PATH, img['file_name'])\n",
    "        if not os.path.exists(img_path):\n",
    "            missing_images.append(img['file_name'])\n",
    "            \n",
    "    print(f\"Total Images in Annotations: {len(coco_data['images'])}\")\n",
    "    print(f\"Missing images: {len(missing_images)}\")\n",
    "    if missing_images:\n",
    "        print(f\"First 5 missing: {missing_images[:5]}\")\n",
    "    else:\n",
    "        print(\"All images found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B: OCR Dataset EDA (Text Recognition)\n",
    "\n",
    "We will analyze the OCR dataset which consists of images and a label file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OCR_DATASET_PATH = \"../datasets/IndonesianLiscenePlateDataset/plate_text_dataset\"\n",
    "LABEL_FILE = os.path.join(OCR_DATASET_PATH, \"label.csv\")\n",
    "OCR_IMAGES_DIR = os.path.join(OCR_DATASET_PATH, \"dataset\")\n",
    "\n",
    "if os.path.exists(LABEL_FILE):\n",
    "    ocr_df = pd.read_csv(LABEL_FILE)\n",
    "    print(f\"Loaded labels from {LABEL_FILE}\")\n",
    "    print(ocr_df.head())\n",
    "    print(f\"Total samples: {len(ocr_df)}\")\n",
    "else:\n",
    "    print(f\"Label file not found at {LABEL_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Text Length Distribution\n",
    "Check the length of the license plate texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'ocr_df' in locals():\n",
    "    # Ensure label is string\n",
    "    ocr_df['label'] = ocr_df['label'].astype(str)\n",
    "    ocr_df['length'] = ocr_df['label'].apply(len)\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.countplot(x='length', data=ocr_df)\n",
    "    plt.title('Text Length Distribution')\n",
    "    plt.xlabel('Length')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Character Set Analysis\n",
    "Identify all unique characters and check for invalid ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'ocr_df' in locals():\n",
    "    all_text = \"\".join(ocr_df['label'].tolist())\n",
    "    unique_chars = sorted(list(set(all_text)))\n",
    "    print(f\"Unique characters ({len(unique_chars)}): {unique_chars}\")\n",
    "    \n",
    "    # Character frequency\n",
    "    char_counts = Counter(all_text)\n",
    "    char_df = pd.DataFrame.from_dict(char_counts, orient='index', columns=['count']).sort_values('count', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    sns.barplot(x=char_df.index, y=char_df['count'])\n",
    "    plt.title('Character Frequency')\n",
    "    plt.xlabel('Character')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Character Balance (Letters vs Numbers)\n",
    "Check the proportion of letters and numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'ocr_df' in locals():\n",
    "    all_text = \"\".join(ocr_df['label'].tolist())\n",
    "    total_chars = len(all_text)\n",
    "    digits = sum(c.isdigit() for c in all_text)\n",
    "    letters = sum(c.isalpha() for c in all_text)\n",
    "    others = total_chars - digits - letters\n",
    "    \n",
    "    print(f\"Total Characters: {total_chars}\")\n",
    "    print(f\"Digits: {digits} ({digits/total_chars*100:.1f}%)\")\n",
    "    print(f\"Letters: {letters} ({letters/total_chars*100:.1f}%)\")\n",
    "    print(f\"Others: {others} ({others/total_chars*100:.1f}%)\")\n",
    "    \n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.pie([digits, letters, others], labels=['Digits', 'Letters', 'Others'], autopct='%1.1f%%')\n",
    "    plt.title('Character Type Distribution')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizing Sample OCR Images\n",
    "Check quality of cropped images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_ocr_samples(ocr_df, images_dir, num_samples=10):\n",
    "    if len(ocr_df) == 0:\n",
    "        return\n",
    "        \n",
    "    samples = ocr_df.sample(num_samples)\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i, (_, row) in enumerate(samples.iterrows()):\n",
    "        img_path = os.path.join(images_dir, row['filename'])\n",
    "        label = row['label']\n",
    "        \n",
    "        if not os.path.exists(img_path):\n",
    "            pass\n",
    "            \n",
    "        if os.path.exists(img_path):\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                plt.subplot(2, 5, i+1)\n",
    "                plt.imshow(img)\n",
    "                plt.title(label)\n",
    "                plt.axis('off')\n",
    "            else:\n",
    "                print(f\"Could not read image: {img_path}\")\n",
    "        else:\n",
    "            print(f\"Image not found: {img_path}\")\n",
    "            \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if 'ocr_df' in locals():\n",
    "    show_ocr_samples(ocr_df, OCR_IMAGES_DIR, num_samples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Image Quality Analysis\n",
    "Analyze brightness, contrast, and resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_image_stats(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return None\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    brightness = np.mean(gray)\n",
    "    contrast = np.std(gray)\n",
    "    h, w = gray.shape\n",
    "    return brightness, contrast, w, h\n",
    "\n",
    "if 'ocr_df' in locals():\n",
    "    brightness_vals = []\n",
    "    contrast_vals = []\n",
    "    widths = []\n",
    "    heights = []\n",
    "    \n",
    "    # Sample 500 images for speed if needed, or all\n",
    "    sample_df = ocr_df.sample(min(len(ocr_df), 500))\n",
    "    \n",
    "    for _, row in tqdm(sample_df.iterrows(), total=len(sample_df), desc=\"Analyzing Image Quality\"):\n",
    "        img_path = os.path.join(OCR_IMAGES_DIR, row['filename'])\n",
    "        if os.path.exists(img_path):\n",
    "            stats = calculate_image_stats(img_path)\n",
    "            if stats:\n",
    "                brightness_vals.append(stats[0])\n",
    "                contrast_vals.append(stats[1])\n",
    "                widths.append(stats[2])\n",
    "                heights.append(stats[3])\n",
    "                \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    sns.histplot(brightness_vals, kde=True)\n",
    "    plt.title('Brightness Distribution')\n",
    "    plt.xlabel('Mean Pixel Value')\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    sns.histplot(contrast_vals, kde=True)\n",
    "    plt.title('Contrast Distribution')\n",
    "    plt.xlabel('Std Dev of Pixel Values')\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    sns.histplot(widths, kde=True)\n",
    "    plt.title('Image Width Distribution')\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    sns.histplot(heights, kde=True)\n",
    "    plt.title('Image Height Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    if heights:\n",
    "        print(f\"Average Size: {np.mean(widths):.1f}x{np.mean(heights):.1f}\")\n",
    "        print(f\"Min Height: {np.min(heights)}, Max Height: {np.max(heights)}\")\n",
    "        small_ocr = [h for h in heights if h < 30]\n",
    "        print(f\"Images with height < 30px: {len(small_ocr)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
